model_5 <- lm(ks4score ~ fiveem + fiveac, data=mani_df)
Anova(model_5)
display(model_5)
```
model_1 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + new_secshort + new_hiquamum + singlepar + house + fsm + parasp, data=mani_df)
Anova(model_1)
```{r}
model_2 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc)  + gender + new_hiquamum + singlepar + house + fsm + parasp, data=mani_df)
Anova(model_2)
```{r}
model_3 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc)  + gender + singlepar + house + fsm + parasp, data=mani_df)
Anova(model_3)
```
remove fsm
```{r}
model_4 <- lm(ks4score ~ fiveem + fiveac +factor(k3en) + factor(k3ma) + factor(k3sc)  + gender + singlepar + house + parasp, data=mani_df)
Anova(model_4)
```{r}
vif(model_4)
display(model_4)
```
```{r}
model_5 <- lm(ks4score ~ factor(k3en) + factor(k3ma) + factor(k3sc) , data=mani_df)
Anova(model_5)
Anova(model_5)
vif(model_5)
display(model_5)
```
```{r}
all_model_1 <- lm(ks4Score ~ iveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + new_secshort + new_hiquamum + singlepar + house + fsm + parasp +computer + tuition + pupasp + homework + attitude + sen + truancy + absent + exclude + IDACI_n + FSMband, data= mani_df)
```{r}
all_model_1 <- lm(ks4score ~ iveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + new_secshort + new_hiquamum + singlepar + house + fsm + parasp +computer + tuition + pupasp + homework + attitude + sen + truancy + absent + exclude + IDACI_n + FSMband, data= mani_df)
```{r}
all_model_1 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + new_secshort + new_hiquamum + singlepar + house + fsm + parasp +computer + tuition + pupasp + homework + attitude + sen + truancy + absent + exclude + IDACI_n + FSMband, data= mani_df)
anova(all_model_1)
```
all_model_1 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + singlepar + house  + parasp +computer  + pupasp + homework + attitude + sen + truancy + absent + exclude + IDACI_n + FSMband, data= mani_df)
anova(all_model_1)
```{r}
model_5 <- lm(ks4score ~ fiveac + fiveem , data=mani_df)
display(model_5)
```
```{r}
model_6 <- lm(ks4score ~ fiveac, data=mani_df)
display(model_6)
```
```{r}
model_6 <- lm(ks4score ~ fiveac, data=mani_df)
display(model_6)
```
```{r}
model_5 <- lm(ks4score ~ fiveac, data=mani_df)
display(model_5)
```
```{r}
model_6 <- lm(ks4score ~ fiveac + fiveem , data=mani_df)
display(model_6)
```
summary(model_5)
```
summary(model_6)
```
display(model_5)
```
display(model_6)
```
```{r}
chisq.test(mani_df$fiveac, mani$fiveem)
```
```{r}
chisq.test(mani_df$fiveac, mani_df$fiveem)
```
summary(model_5)
```
summary(model_6)
```
The fact that adding fiveem to the model leads to a marginally tiny increase in R statistics increases marginally small from model_5 to model_6 showing a weak
display(model_4)
```
summary(model_4)
```
```{r}
model_7 <- lm(ks4score ~ fiveem +factor(k3en) + factor(k3ma) + factor(k3sc)  + gender + singlepar + house + parasp, data=mani_df)
summary(model_7)
```
```{r}
model_8 <- lm(ks4score ~ fiveac + factor(k3en), data=mani_df)
summary(model_8)
```
```{r}
model_8 <- lm(ks4score ~ IDACI_n + fiveac, data=mani_df)
display(model_8)
```
```{r}
model_9 <- lm(ks4score ~ IDACI_n + fiveem, data=mani_df)
display(model_9)
```
display(model_9)
summary(model_9)
```
```{r }
p15 <- ggplot(mani_df, aes(x=IDACI_n, y=fiveem), color = fiveem) + geom_point() + geom_smooth(methods = "lm")
```{r }
p15 <- ggplot(mani_df, aes(x=IDACI_n, y=fiveem), color = fiveem) + geom_point() + geom_smooth(method = "lm")
```{r }
p15 <- ggplot(mani_df, aes(x=IDACI_n, y=ks4score), color = fiveem) + geom_point() + geom_smooth(method = "lm")
p16 <- ggplot(mani_df, aes(x=IDACI_n, y=ks4score), color = fiveac) + geom_point() + geom_smooth(methods = "lm")
p16 <- ggplot(mani_df, aes(x=IDACI_n, y=ks4score), color = fiveac) + geom_point() + geom_smooth(method = "lm")
grid.arrange(p15,p16,nrow=1)
```
```{r }
p15 <- ggplot(mani_df, aes(x=IDACI_n, y=ks4score), colour = fiveem) + geom_point() + geom_smooth(method = "lm")
p16 <- ggplot(mani_df, aes(x=IDACI_n, y=ks4score), colour = fiveac) + geom_point() + geom_smooth(method = "lm")
grid.arrange(p15,p16,nrow=1)
```
```{r }
p17 <- ggplot(mani_df, aes(x=IDACI_n, y=ks4score), colour = fiveem) + geom_point() + geom_smooth(method = "lm")
grid.arrange(p17,p16,nrow=1)
```
library(arm)
library(arm)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(car)
rw_df <- read.csv("RWNS_final.csv", header = TRUE)
head(rw_df, 5)
colnames(rw_df)
summary(rw_df)
p1 <- ggplot(rw_df, aes(x= fiveem, y=ks4score)) + geom_boxplot()
p2 <- ggplot(rw_df, aes(x= fiveac, y=ks4score)) + geom_boxplot()
p3 <- ggplot(rw_df, aes(x= factor(k3en), y=ks4score)) + geom_boxplot() + labs(x="English Score Tier")
p4 <- ggplot(rw_df, aes(x= factor(k3ma), y=ks4score)) + geom_boxplot() + labs(x="Maths Score Tier")
p5 <- ggplot(rw_df, aes(x= factor(k3sc), y=ks4score)) + geom_boxplot() +  labs(x="Science Score Tier")
p6 <- ggplot(rw_df, aes(x= gender, y=ks4score)) + geom_boxplot()
p7 <- ggplot(rw_df, aes(x= SECshort, y=ks4score)) + geom_boxplot()
p8 <- ggplot(rw_df, aes(x= hiquamum, y=ks4score)) + geom_boxplot()
p9 <- ggplot(rw_df, aes(x= singlepar, y=ks4score)) + geom_boxplot()
p10 <- ggplot(rw_df, aes(x= house, y=ks4score)) + geom_boxplot()
p11 <- ggplot(rw_df, aes(x= fsm, y=ks4score)) + geom_boxplot()
p12 <- ggplot(rw_df, aes(x= parasp, y=ks4score)) + geom_boxplot()
grid.arrange(p1, p2, p3, p4, ncol =2, nrow=2)
grid.arrange(p5, p6, p9, p10, p11, p12, ncol =3, nrow=2)
p7 <- p7 +  theme(axis.text.x = element_text(angle = 30, vjust = 1, hjust=1))
p8 <- p8 + theme(axis.text.x = element_text(angle = 30, vjust = 1, hjust=1))
grid.arrange( p7, p8, ncol =2, nrow=1)
model_1 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + new_secshort + new_hiquamum + singlepar + house + fsm + parasp, data=mani_df)
model_1 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + SECshort + hiquamum + singlepar + house + fsm + parasp, data=rw_df)
Anova(model_1)
```{r}
model_2 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc)  + gender + new_hiquamum + singlepar + house + fsm + parasp, data=mani_df)
Anova(model_2)
```
remove new_hiquamum from the model
```{r}
model_2 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc)  + gender + hiquamum + singlepar + house + fsm + parasp, data=rw_df)
Anova(model_2)
```
remove new_hiquamum from the model
```{r}
model_3 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + hiquamum + gender + singlepar + house + parasp, data=mani_df)
```{r}
model_3 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + hiquamum + gender + singlepar + house + parasp, data=rw_df)
Anova(model_3)
```
remove fsm
Anova(model_3)
vif(model_3)
```
```{r}
model_4 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma)  + gender + singlepar + house + parasp, data=mani_df)
```{r}
model_4 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma)  + gender + singlepar + house + parasp, data=rw_df)
Anova(model_4)
```
```{r}
model_4 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma)  + gender + singlepar + house + parasp + hiquamum, data=rw_df)
Anova(model_4)
```
```{r}
vif(model_4)
summary(model_4)
```
```{r}
model_4 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma)+ factor(k3sc)  + gender + singlepar + house + parasp + hiquamum, data=rw_df)
Anova(model_4)
```
```{r}
vif(model_4)
summary(model_4)
```
```{r}
model_7 <- lm(ks4score ~ fiveem + factor(k3en) + factor(k3ma)  + gender + singlepar + house + parasp, data=mani_df)
```{r}
model_5 <- lm(ks4score ~ fiveem + factor(k3en) + factor(k3ma)  + gender + singlepar + house + parasp, data=mani_df)
vif(model_5)
summary(model_5)
```
```{r}
model_5 <- lm(ks4score ~ fiveem + factor(k3en) + factor(k3ma)  + gender + singlepar + house + parasp, data=rw_df)
vif(model_5)
```{r}
model_5 <- lm(ks4score ~ fiveem + factor(k3en) + gender + singlepar + house + parasp, data=rw_df)
vif(model_5)
summary(model_5)
```
```{r}
mani_df <- rw_df
mani_df$new_secshort <- rw_df$SECshort
levels(mani_df$new_secshort)[levels(mani_df$new_secshort) %in% c("Intermediate","Routine,_semi-routine_or_unemployed")] <- "non-professional"
levels(mani_df$new_secshort)[levels(mani_df$new_secshort) %in% c("Managerial_and_professional")] <- "professional"
mani_df$new_secshort <- factor(mani_df$new_secshort, ordered = FALSE)
mani_df$new_secshort <- relevel(mani_df$new_secshort , ref="non-professional")
View(mani_df)
```{r}
mani_df <- rw_df
mani_df$new_secshort <- rw_df$SECshort
levels(mani_df$new_secshort)[levels(mani_df$new_secshort) %in% c("Intermediate","Routine,_semi-routine_or_unemployed")] <- "non-professional"
levels(mani_df$new_secshort)[levels(mani_df$new_secshort) %in% c("Managerial_and_professional")] <- "professional"
mani_df$new_secshort <- factor(mani_df$new_secshort, ordered = FALSE)
mani_df$new_secshort <- relevel(mani_df$new_secshort , ref="non-professional")
levels(mani_df$new_secshort)[levels(mani_df$new_secshort) %in% c("Intermediate","Routine,_semi-routine_or_unemployed")] <- "non-professional"
levels(mani_df$new_secshort)[levels(mani_df$new_secshort) %in% c("Managerial_and_professional")] <- "professional"
mani_df$new_secshort <- relevel(mani_df$new_secshort , ref="non-professional")
summary(mani_df$new_secshort)
```
```{r}
mani_df$new_hiquamum <- mani_df$hiquamum
mani_df$new_hiquamum <- factor(mani_df$new_hiquamum, ordered = FALSE)
levels(mani_df$new_hiquamum)[levels(mani_df$new_hiquamum) %in% c("No_qualification","Other_qualifications","GCSE_grades_A-C_or_equiv","GCE_A_Level_or_equivalent","HE_below_degree_level")] <- "no-degree"
levels(mani_df$new_hiquamum)[levels(mani_df$new_hiquamum) %in% c("Degree_or_equivalent")] <- "degree-equivalent"
mani_df$new_hiquamum <- relevel(mani_df$new_hiquamum, ref="no-degree")
summary(mani_df$new_hiquamum)
```
```{r}
missing <- sum(rw_df$singlepar == "missing")
110/13589
model_1 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + new_secshort + new_hiquamum + singlepar + house + fsm + parasp, data=mani_df)
Anova(model_1)
```
```{r}
model_2 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + new_hiquamum + singlepar + house + fsm + parasp, data=mani_df)
Anova(model_2)
```
remove fsm from the model
```{r}
model_2 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + new_hiquamum + singlepar + house + fsm + parasp, data=mani_df)
Anova(model_2)
```
```{r}
model_3 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + hiquamum + gender + singlepar + house + parasp, data=rw_df)
```{r}
model_3 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + singlepar + house + fsm + parasp, data=mani_df)
Anova(model_3)
remove fsm
```{r}
model_4 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma) + factor(k3sc) + gender + singlepar + house + parasp, data=mani_df)
Anova(model_3)
Anova(model_4)
vif(model_4)
```
remove k3sc because highly correlated with k3ma
```{r}
model_5 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma)  + gender + singlepar + house + parasp, data=rw_df)
Anova(model_5)
```
vif(model_5)
```
vif(model_6)
K3ma and k3sc have high VIF values, 11.67 and 12.9 respectively indicating a problematic amount of colinearity.
remove k3sc because highly correlated with k3ma
```{r}
model_5 <- lm(ks4score ~ fiveem + fiveac + factor(k3en) + factor(k3ma)  + gender + singlepar + house + parasp, data=mani_df)
vif(model_5)
```
model_6 <- lm(ks4score ~ fiveac + factor(k3en) + gender + singlepar + house + parasp, data=mani_df)
vif(model_6)
summary(model_6)
```
display(model_6)
```
install.packages("ISLR2")
library(ISLR2)
names(Smarket)
summary(Smarket)
cor(Smarket[,-9])
lm.1 <- glm(Direction ~. -Year, data = Smarket, family = binomial)
summary(lm.1)
lm.1 <- glm(Direction ~. -Year-Today, data = Smarket, family = binomial)
summary(lm.1)
summary(lm.1)$coef
lm.pred <- predict(lm.1, type = "response")
lm.pred[1:10]
lm.pred <- rep("Down", 1250)
lm.pews[lm.prob > .5] = "Up"
lm.pred[lm.prob > .5] = "Up"
lm.prob <- predict(lm.1, type = "response")
lm.prob[1:10] #probabilities
lm.pred <- rep("Down", 1250)
lm.pred[lm.prob > .5] = "Up"
#produce confusion matrix
table(lm.pred, Smarket$Direction)
mean(lm.pred == Smarket$Direction)
train <- (Year < 2005)
train <- (Smarket$Year < 2005)
S.market.2005 <- Smarket[!train,]
Direction.2005 <- Smarket&Direction[!train]
Direction.2005 <- Smarket$Direction[!train]
lm.2 < glm(Direction ~. -Today-Year, data = Smarket, family = binomial, subset = train)
lm.2 <- glm(Direction ~. -Today-Year, data = Smarket, family = binomial, subset = train)
lm.prob <- predict(lm.2, S.market.2005)
lm.prob".2" <- predict(lm.2, S.market.2005, type = "response")
lm.pred.2 <- rep("Down", 1250)
lm.pred.2[lm.prob.2 > .5] = "Up"
lm.prob.2 <- predict(lm.2, S.market.2005, type = "response")
lm.pred.2 <- rep("Down", 1250)
lm.pred.2[lm.prob.2 > .5] = "Up"
table(lm.pred.2,Direction.2005)
lm.pred.2 <- rep("Down", 250)
lm.pred.2[lm.prob.2 > .5] = "Up"
table(lm.pred.2, Direction.2005)
mean(lm.pred.2 == Direction.2005)
setwd("~/GitHub/Rstudio/Applied-Regression/logistics regression")
library(arm)
library(ggplot2)
library(gridExtra)
library(car)
icu.dat<-read.csv("ICUdeaths.csv", header=TRUE)
head(icu.dat, 5)
icu.dat<-read.csv("ICUdeaths.csv", header=TRUE, stringsAsFactors = TRUE)
head(icu.dat, 5)
summary(icu.dat)
p1<- ggplot(icu.dat, aes(x=factor(Lived), y=Age))+ geom_boxplot()+ coord_flip()
p1<-p1+theme(legend.position = "none")
p2<- ggplot(icu.dat, aes(x=factor(Lived), y=SBP))+ geom_boxplot()+ coord_flip()
p2<-p2+theme(legend.position = "none")
p3<- ggplot(icu.dat, aes(x=factor(Lived), y=HR))+ geom_boxplot()+ coord_flip()
p3<-p3+theme(legend.position = "none")
#cross tabulation plot: are two categorical variables related?
p4<- ggplot(icu.dat,aes(x = factor(Sex), fill = factor(Lived))) +
geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage"
, labels = scales::percent)
grid.arrange(p1,p2,p3,p4,nrow=2)
#GLM
icu.glm<-glm(Lived~Age,data=icu.dat,family=binomial(link="logit"))
display(icu.glm)
summary(icu.glm)
exp(-0.04)
#odds ratio assoc with an increase in 1 year. exp(-0.04) = 0.94
invlogit(3.15-0.04*20)
invlogit(3.15-0.04*50)
0.91/0.76
library(dplyr)
icu.breaks<-mutate(icu.dat, bin=cut(Age,breaks = seq(15, 95, by=5)))
#estimate the proportion of people that survived the ICU in each bin (y-axis)
prop <- prop.table(with(icu.breaks, table(Lived,bin)),2)[2,]
# the midpoint of each bin (x-axis)
midbin<- seq(17.5, 92.5, by=5)
#create a new data frame using these two variables
icu.bin<-data.frame(midbin,prop)
## ----the logistic plot----
#basic plot
p1<- ggplot(icu.breaks,aes(x=Age,y=Lived))
p1
# geom_count is a type of point that takes into account how frequent that value is
# it plots the Lived/not Lived
p1<-p1+ geom_count()
p1
#adds the logisitc regression line of best fit
p1<-p1+ geom_smooth(method = "glm", method.args = list(family = "binomial"),se = FALSE)
#plots the points corresponding to the proportions
p1<-p1+ geom_point(data=icu.bin, aes(x=midbin,y=prop),shape=2,color="red", size=3)
p1
icu.dat.shape
((19+152)/(96+141))
## ---------centering---------------------------------------------------------------
cent.Age<-with(icu.dat, (Age-mean(Age)))
cent.age.glm<-glm(Lived~cent.Age, data=icu.dat, family = binomial(link="logit"))
display(cent.age.glm)
## ------------------predicting------------------------------------------------------
pred.glm<-as.numeric(icu.glm$fitted.values>0.5)
glm.dat<-data.frame(predicted=pred.glm, observed=icu.dat$Lived)
table(glm.dat)
## ----------------------table of percentages correct--------------------------------------------------
round(prop.table(with(icu.dat, table(Lived,Sex)),2),2)
## -----------------------fake data-------------------------------------------------
#fake data with an association:
#A binary with 30 1's and 50 0's.
A<-c(rep(1,30),rep(0,50))
#rbinom generates n binary random variables with p(x=1)=p.
#size picks a sample of size from these
B<-ifelse(A==1,rbinom(n=100,size=1,p=0.2),rbinom(n=100,size=1,p=0.8))
#There is a strong dependence between A and B
AB<-data.frame(A=A, B=B)
round(prop.table(table(A,B),2),2)
## ----plots to compare-------------
p1<- ggplot(icu.dat,aes(x = factor(Sex), fill = factor(Lived))) +
geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage"
, labels = scales::percent)
p1<-p1+ labs(tag = "A")
p2<- ggplot(data=data.frame(A,B),aes(x = factor(A), fill = factor(B))) +
geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage"
, labels = scales::percent)
p2<-p2+ labs(tag = "B")
grid.arrange(p1,p2,nrow=1)
library(arm)
library(ggplot2)
library(gridExtra)
library(car)
library(dplyr)
gym.df <- read.table("src/Health.txt", header = True, stringsAsFactors = True)
gym.df <- read.table("src\Health.txt", header = True, stringsAsFactors = True)
gym.df <- read.table("src/Health.txt", header = True, stringsAsFactors = True)
gym.df <- read.delim("src/Health.txt", header = True, stringsAsFactors = True)
gym.df <- read.table("src/Health.txt", sep = ",", header = True, stringsAsFactors = True)
library(gridExtra)
gym.df <- read.table("src/Health.txt", sep = ",", header = TRUE, stringsAsFactors = TRUE)
head(gym.df, 5)
gym.df <- read.table("src/Health.txt", header = TRUE, stringsAsFactors = TRUE)
head(gym.df, 5)
summary(gym.df)
#prejudice boxplot
p1 <- (gym.df,aes(x = Age, fill = factor(Health))) +  geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage", labels = scales::percent)
#prejudice boxplot
p1 <- (gym.df,aes(x = Age, fill = factor(Health))) +  geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage", labels = scales::percent)
#prejudice boxplot
p1 <- ggplot(gym.df,aes(x = Age, fill = factor(Health))) +  geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage", labels = scales::percent)
p1
#prejudice boxplot
p1 <- ggplot(gym.df,aes(x = Age, fill = factor(Health))) + geom_boxplot()+ coord_flip()
p1
p2 <- ggplot(gym.df,aes(x = Income, fill = factor(Health))) + geom_boxplot()+ coord_flip()
p3 <- ggplot(gym.df,aes(x = Gender, fill = factor(Health))) +  geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage", labels = scales::percent)
p4 <- ggplot(gym.df,aes(x = Member, fill = factor(Health))) +  geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage", labels = scales::percent)
grid.arrange(p1,p2,p3,p4, nrow=2)
#prejudice boxplot
p1 <- ggplot(gym.df,aes(x = Age, fill = factor(Health))) + geom_boxplot()+ coord_flip() +theme(legend.position = "none")
p2 <- ggplot(gym.df,aes(x = Income, fill = factor(Health))) + geom_boxplot()+ coord_flip()+theme(legend.position = "none")
p3 <- ggplot(gym.df,aes(x = Gender, fill = factor(Health))) +  geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage", labels = scales::percent)+theme(legend.position = "none")
p4 <- ggplot(gym.df,aes(x = Member, fill = factor(Health))) +  geom_bar(position = "fill") +  scale_y_continuous(name = "Within group Percentage", labels = scales::percent)
grid.arrange(p1,p2,p3,p4, nrow=2)
#regression
lm.1 <- lm(Health ~ Member, gym.df, family=binomial(link="logit"))
#regression
lm.1 <- glm(Health ~ Member, gym.df, family=binomial(link="logit"))
#regression
g <- glm(Health ~ Member, gym.df, family=binomial(link="logit"))
#regression
glm.1 <- glm(Health ~ Member, gym.df, family=binomial(link="logit"))
display(glm.1)
invlogit(0.37)
#prediction table
pred.glm.1<-as.numeric((health.glm.1$fitted.values>0.5))
#prediction table
pred.glm.1<-as.numeric((glm.1$fitted.values>0.5))
glm.1$fitted.values
glm.dat.1<-data.frame(predicted=pred.glm.1, observed=gym.df$Health)
table(glm.dat.1)
View(glm.dat.1)
pred.glm.1[glm.1$fitted.values > 0.5] = 1
glm.dat.1<-data.frame(predicted=pred.glm.1, observed=gym.df$Health)
table(glm.dat.1)
pred.glm.1[glm.1.prob > 0.5] = 1
#prediction table
pred.glm.1<-as.numeric((glm.1$fitted.values>0.5))
glm.dat.1<-data.frame(predicted=pred.glm.1, observed=gym.df$Health)
table(glm.dat.1)
glm.2 < - glm(Health ~. gym.df, family=binomial(link="logit")))
glm.2 < - glm(Health ~. gym.df, family=binomial(link="logit"))
glm.2 < - glm(Health ~. ,gym.df, family=binomial(link="logit"))
glm.2 < - glm(Health ~. ,gym.df, family=binomial(link="logit"))
glm.2 < - glm(Health ~. , gym.df, family=binomial(link="logit"))
glm.2 <- glm(Health ~. , gym.df, family=binomial(link="logit"))
summary(glm.2)
summary(glm.1)
#plot
health.breaks<-mutate(gym.dt, bin=cut(Age,breaks = seq(20, 75, by=5))
prop <- prop.table(with(health.breaks, table(Health,bin)),2)[2,]
#plot
health.breaks<-mutate(gym.dt, bin=cut(Age,breaks = seq(20, 75, by=5))
#plot
health.breaks<-mutate(gym.dt, bin=cut(Age,breaks = seq(20, 75, by=5))
#plot
health.breaks<-mutate(gym.dt, bin=cut(Age,breaks = seq(20, 75, by=5)))
#plot
health.breaks<-mutate(gym.df, bin=cut(Age,breaks = seq(20, 75, by=5)))
prop <- prop.table(with(health.breaks, table(Health,bin)),2)[2,]
View(health.breaks)
prop
prop <- prop.table(with(health.breaks, table(Health,bin)),2)
prop
prop <- prop.table(with(health.breaks, table(Health,bin)),2)[2,]
midbin<- seq(22.5, 72.5, by=5)
health.bin<-data.frame(midbin,prop)
health.bin
p5<- ggplot(health.breaks,aes(x=Age,y=Health)) + geom_cou
p5<- ggplot(health.breaks,aes(x=Age,y=Health)) + geom_count()
p5<- p5 + geom_smooth(method = "glm", method.args = list(family = "binomial"),se = FALSE)
p5
p5 <- p5 +  geom_point(data=health.bin, aes(x=midbin,y=prop),shape=2,color="red", size=3)
p5
summary(gym.df)
summary(glm.2)
invlogit(3.714-01102*20)
invlogit(3.714-0.1102*20)
invlogit(3.714-0.1102*25)
0.8190612-0.7229215
invlogit(3.714-0.1102*50
)
invlogit(3.714-0.1102*55)
0.1423-0.873
0.1423-0.0873
